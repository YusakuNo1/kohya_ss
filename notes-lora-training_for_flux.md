# è¿›å…¥ç¯å¢ƒ
conda activate kohya_ss

# æ‰§è¡Œè®­ç»ƒ

æ¯æ¬¡canceläº†ä¹‹åï¼ŒGPUè¿˜åœ¨å ç”¨ï¼Œè¿è¡Œ`pkill -9 python`æ¸…ç†

## Training 1, very slow
```
accelerate launch --num_cpu_threads_per_process 8 \
  "./sd-scripts/flux_train_network.py" \
  --pretrained_model_name_or_path "./models/FLUX.1-dev/flux1-dev.safetensors" \
  --clip_l "./models/FLUX.1-dev/text_encoder/model.safetensors" \
  --t5xxl "./models/FLUX.1-dev/t5xxl_fp8_e4m3fn.safetensors" \
  --ae "./models/FLUX.1-dev/ae.safetensors" \
  --train_data_dir "./test_train" \
  --output_dir "./outputs" \
  --output_name "EWOLiyingZhao_Flux_v1" \
  --save_model_as safetensors \
  --sdpa \
  --mixed_precision bf16 \
  --network_module networks.lora_flux \
  --network_dim 32 \
  --network_alpha 16 \
  --resolution "512,512" \
  --train_batch_size 2 \
  --max_train_steps 2000 \
  --save_every_n_steps 500 \
  --learning_rate 1e-4 \
  --optimizer_type "AdamW8bit" \
  --cache_latents \
  --cache_latents_to_disk \
  --gradient_checkpointing \
  --save_precision bf16 \
  --caption_extension ".txt"
```

## Training 2 (è®­ç»ƒåç¼©ï¼Œåªèƒ½äº§ç”Ÿé›ªèŠ±å›¾)

```
accelerate launch --num_cpu_threads_per_process 4 \
  "./sd-scripts/flux_train_network.py" \
  --pretrained_model_name_or_path "./models/FLUX.1-dev/flux1-dev.safetensors" \
  --clip_l "./models/FLUX.1-dev/text_encoder/model.safetensors" \
  --t5xxl "./models/FLUX.1-dev/t5xxl_fp8_e4m3fn.safetensors" \
  --ae "./models/FLUX.1-dev/ae.safetensors" \
  --train_data_dir "./test_train" \
  --output_dir "./outputs" \
  --output_name "EWOLiyingZhao_Flux_v1" \
  --sdpa --mixed_precision bf16 \
  --network_module networks.lora_flux \
  --network_dim 32 --network_alpha 16 \
  --resolution "512,512" \
  --train_batch_size 2 \
  --max_train_steps 2000 \
  --learning_rate 1e-4 \
  --optimizer_type "AdamW8bit" \
  --cache_latents \
  --cache_text_encoder_outputs \
  --gradient_checkpointing \
  --save_precision bf16 \
  --caption_extension ".txt"
```

## Training 3

å¯ä»¥è®­ç»ƒï¼Œä½†æœ€åå‡ºæ¥æƒé‡æ˜¯0.5æˆ–æ›´é«˜ï¼Œå…¨æ˜¯é›ªèŠ±ï¼Œå¦‚æœæ˜¯0.1ï¼Œå¯ä»¥å‡ºå›¾ï¼Œä½†ä¸åƒã€‚è®¾ç½®æƒé‡

```python
print(f"ğŸ¨ æ³¨å…¥ LoRA æƒé‡å¹¶è®¾ç½®å¼ºåº¦...")
# 1. å…ˆåŠ è½½æƒé‡
pipe.load_lora_weights(LORA_PATH, adapter_name="yusaku")

# 2. è®¾ç½®æä½å¼ºåº¦ (0.1) æ¥æ’æŸ¥æ˜¯å¦æƒé‡æº¢å‡º
# å¦‚æœ 0.1 èƒ½å‡ºå›¾ï¼Œè¯´æ˜ LoRA è¿˜èƒ½æ•‘ï¼›å¦‚æœ 0.1 è¿˜æ˜¯é›ªèŠ±ï¼Œè¯´æ˜æƒé‡å½»åº•ç‚¸äº†ã€‚
pipe.set_adapters(["yusaku"], adapter_weights=[0.1]) 

print("âš¡ 5090 æ­£åœ¨ä»¥ 0.1 å¼ºåº¦è¿›è¡Œé™å‹æ¨ç†...")
```

æ ¸å¿ƒæ”¹åŠ¨ï¼š
1. åˆ†è¾¨ç‡åŠ¡å¿…æ”¹å› 1024,1024
2. é™ä½å­¦ä¹ ç‡ï¼Œé˜²æ­¢å†æ¬¡åç¼© (æ¨è 5e-5 æˆ– 1e-4)
3. å¼€å¯æ˜¾å­˜ä¼˜åŒ–ï¼Œç¡®ä¿ 32GB ç¨³è·‘

```
accelerate launch --num_cpu_threads_per_process 4 \
  "./sd-scripts/flux_train_network.py" \
  --pretrained_model_name_or_path "./models/FLUX.1-dev/flux1-dev.safetensors" \
  --clip_l "./models/FLUX.1-dev/text_encoder/model.safetensors" \
  --t5xxl "./models/FLUX.1-dev/t5xxl_fp8_e4m3fn.safetensors" \
  --ae "./models/FLUX.1-dev/ae.safetensors" \
  --train_data_dir "./test_train" \
  --output_dir "./outputs" \
  --output_name "EWOLiyingZhao_Flux_v2_1024" \
  --resolution "1024,1024" \
  --train_batch_size 1 \
  --max_train_steps 1500 \
  --save_every_n_steps 250 \
  --learning_rate 5e-5 \
  --network_dim 16 \
  --network_alpha 8 \
  --optimizer_type "AdamW8bit" \
  --mixed_precision bf16 \
  --sdpa \
  --cache_latents \
  --cache_text_encoder_outputs \
  --gradient_checkpointing
```

## Training 4

### ä»0åˆ°1000 stepï¼ˆä¼šå‡ºç°é›ªèŠ±ï¼‰
```
accelerate launch --num_cpu_threads_per_process 2 \
  "./sd-scripts/flux_train_network.py" \
  --pretrained_model_name_or_path "./models/FLUX.1-dev/flux1-dev.safetensors" \
  --clip_l "./models/FLUX.1-dev/text_encoder/model.safetensors" \
  --t5xxl "./models/FLUX.1-dev/t5xxl_fp8_e4m3fn.safetensors" \
  --ae "./models/FLUX.1-dev/ae.safetensors" \
  --network_module networks.lora_flux \
  --train_data_dir "./test_train" \
  --output_dir "./outputs" \
  --output_name "EWOLiyingZhao_Flux_v5_Success" \
  --resolution "1024,1024" \
  --network_dim 32 \
  --network_alpha 16 \
  --train_batch_size 1 \
  --max_train_steps 2500 \
  --save_every_n_steps 500 \
  --learning_rate 1e-4 \
  --optimizer_type "AdamW" \
  --mixed_precision bf16 \
  --sdpa \
  --cache_latents \
  --cache_text_encoder_outputs \
  --gradient_checkpointing \
  --save_precision bf16 \
  --lowram \
  --caption_extension ".txt"
```

### step 1000å¼€å§‹ç²¾ä¿®

```
accelerate launch --num_cpu_threads_per_process 2 \
  "./sd-scripts/flux_train_network.py" \
  --pretrained_model_name_or_path "./models/FLUX.1-dev/flux1-dev.safetensors" \
  --clip_l "./models/FLUX.1-dev/text_encoder/model.safetensors" \
  --t5xxl "./models/FLUX.1-dev/t5xxl_fp8_e4m3fn.safetensors" \
  --ae "./models/FLUX.1-dev/ae.safetensors" \
  --network_module networks.lora_flux \
  --network_weights "./outputs/EWOLiyingZhao_Flux_v5_Success-step00001000.safetensors" \
  --train_data_dir "./test_train" \
  --output_dir "./outputs" \
  --output_name "EWOLiyingZhao_Flux_v6_Refined" \
  --resolution "1024,1024" \
  --network_dim 32 \
  --network_alpha 16 \
  --train_batch_size 1 \
  --max_train_steps 600 \
  --save_every_n_steps 200 \
  --learning_rate 2e-5 \
  --optimizer_type "AdamW" \
  --mixed_precision bf16 \
  --sdpa \
  --cache_latents \
  --cache_text_encoder_outputs \
  --gradient_checkpointing \
  --save_precision bf16 \
  --lowram \
  --caption_extension ".txt"
```

## Training 5

```
accelerate launch --num_cpu_threads_per_process 2 \
  "./sd-scripts/flux_train_network.py" \
  --pretrained_model_name_or_path "./models/FLUX.1-dev/flux1-dev.safetensors" \
  --clip_l "./models/FLUX.1-dev/text_encoder/model.safetensors" \
  --t5xxl "./models/FLUX.1-dev/t5xxl_fp8_e4m3fn.safetensors" \
  --ae "./models/FLUX.1-dev/ae.safetensors" \
  --network_module networks.lora_flux \
  --train_data_dir "./test_train" \
  --output_dir "./outputs" \
  --output_name "EWOLiyingZhao_Flux_Final_v7" \
  --resolution "1024,1024" \
  --network_dim 16 \
  --network_alpha 1 \
  --train_batch_size 1 \
  --max_train_steps 1500 \
  --learning_rate 4e-5 \
  --optimizer_type "AdamW" \
  --mixed_precision bf16 \
  --sdpa \
  --cache_latents \
  --cache_text_encoder_outputs \
  --gradient_checkpointing \
  --save_precision bf16 \
  --lowram
  ```
  